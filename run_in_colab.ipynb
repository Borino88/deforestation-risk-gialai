{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb3j958HvZBq",
        "outputId": "b16095b3-5d5f-4cd2-fa3c-fd79e5450016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project created at: /content/deforestation_risk_project\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pandas numpy scikit-learn matplotlib\n",
        "\n",
        "import os, textwrap, pathlib\n",
        "from datetime import datetime\n",
        "\n",
        "PROJECT_DIR = \"/content/deforestation_risk_project\"\n",
        "SRC_DIR = f\"{PROJECT_DIR}/src\"\n",
        "OUT_DIR = f\"{PROJECT_DIR}/outputs\"\n",
        "for p in [SRC_DIR, f\"{OUT_DIR}/tables\", f\"{OUT_DIR}/figures\", f\"{OUT_DIR}/predictions\"]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "print(\"Project created at:\", PROJECT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_code = r'''\n",
        "import os, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score,\n",
        "    precision_recall_curve, roc_curve\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _rename_ci(df, targets):\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    for t in targets:\n",
        "        if t not in df.columns and t.lower() in lower:\n",
        "            df = df.rename(columns={lower[t.lower()]: t})\n",
        "    return df\n",
        "\n",
        "def _best_f1_threshold(y_true, scores):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, scores)\n",
        "    f1 = (2*prec*rec)/(prec+rec+1e-12)\n",
        "    i = int(np.nanargmax(f1))\n",
        "    if i == 0 or i-1 >= len(thr):\n",
        "        return 0.5\n",
        "    return float(thr[i-1])\n",
        "\n",
        "def _capture_rate(y_true, scores, top_frac):\n",
        "    y_true = np.asarray(y_true)\n",
        "    scores = np.asarray(scores)\n",
        "    k = max(1, int(math.ceil(top_frac * len(y_true))))\n",
        "    idx = np.argsort(-scores)[:k]\n",
        "    return float(y_true[idx].sum() / max(1, y_true.sum()))\n",
        "\n",
        "def _save_roc(y_true, score_dict, out_path, title):\n",
        "    plt.figure(figsize=(7,5))\n",
        "    for name, sc in score_dict.items():\n",
        "        fpr, tpr, _ = roc_curve(y_true, sc)\n",
        "        plt.plot(fpr, tpr, label=name)\n",
        "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "def run_pipeline(\n",
        "    kbang_train_path,\n",
        "    kbang_test_path,\n",
        "    mang_train_path,\n",
        "    mang_test_path,\n",
        "    out_dir\n",
        "):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    tables_dir = os.path.join(out_dir, \"tables\")\n",
        "    figs_dir = os.path.join(out_dir, \"figures\")\n",
        "    preds_dir = os.path.join(out_dir, \"predictions\")\n",
        "    for p in [tables_dir, figs_dir, preds_dir]:\n",
        "        os.makedirs(p, exist_ok=True)\n",
        "\n",
        "    # 1) Load\n",
        "    dfs = {\n",
        "        \"KBang_train\": pd.read_csv(kbang_train_path),\n",
        "        \"KBang_test\": pd.read_csv(kbang_test_path),\n",
        "        \"MangYang_train\": pd.read_csv(mang_train_path),\n",
        "        \"MangYang_test\": pd.read_csv(mang_test_path),\n",
        "    }\n",
        "    for k in dfs:\n",
        "        dfs[k].columns = [c.strip() for c in dfs[k].columns]\n",
        "\n",
        "    def add_required(df, district, split):\n",
        "        df = df.copy()\n",
        "        df[\"district\"] = district\n",
        "        df[\"split\"] = split\n",
        "\n",
        "        # lon/lat normalization\n",
        "        for c in [\"lon\",\"lat\"]:\n",
        "            if c not in df.columns and c.upper() in df.columns:\n",
        "                df = df.rename(columns={c.upper(): c})\n",
        "\n",
        "        # label_std fallback\n",
        "        if \"label_std\" not in df.columns:\n",
        "            if \"label\" in df.columns:\n",
        "                df[\"label_std\"] = df[\"label\"]\n",
        "            elif \"defo\" in df.columns:\n",
        "                df[\"label_std\"] = df[\"defo\"]\n",
        "            elif \"loss_any_2001_2024\" in df.columns:\n",
        "                df[\"label_std\"] = df[\"loss_any_2001_2024\"]\n",
        "            else:\n",
        "                df[\"label_std\"] = np.nan\n",
        "\n",
        "        df[\"label_std\"] = pd.to_numeric(df[\"label_std\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "        return df\n",
        "\n",
        "    combined = pd.concat([\n",
        "        add_required(dfs[\"KBang_train\"], \"KBang\", \"train\"),\n",
        "        add_required(dfs[\"KBang_test\"], \"KBang\", \"test\"),\n",
        "        add_required(dfs[\"MangYang_train\"], \"MangYang\", \"train\"),\n",
        "        add_required(dfs[\"MangYang_test\"], \"MangYang\", \"test\"),\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    targets = [\n",
        "        \"lon\",\"lat\",\"treecover2000\",\"mean_elevation_m\",\"mean_slope_deg\",\n",
        "        \"rain_last12m_total_mm\",\"rain_mean_annual_2000_2024_mm\",\n",
        "        \"loss_any_2001_2024\",\"loss_first_year\"\n",
        "    ]\n",
        "    combined = _rename_ci(combined, targets)\n",
        "\n",
        "    # 2) QC Summary\n",
        "    qc = {\n",
        "        \"rows\": int(len(combined)),\n",
        "        \"cols\": int(combined.shape[1]),\n",
        "        \"district_counts\": combined[\"district\"].value_counts().to_dict(),\n",
        "        \"split_counts\": combined[\"split\"].value_counts().to_dict(),\n",
        "        \"pos_rate_label_std\": float(combined[\"label_std\"].mean()),\n",
        "    }\n",
        "    core_cols = [c for c in targets if c in combined.columns]\n",
        "    qc[\"missing_core\"] = {c: int(combined[c].isna().sum()) for c in core_cols}\n",
        "    if \"lon\" in combined.columns and \"lat\" in combined.columns:\n",
        "        qc[\"duplicate_lonlat_rows\"] = int(combined.duplicated(subset=[\"lon\",\"lat\"]).sum())\n",
        "    pd.DataFrame([qc]).to_csv(os.path.join(out_dir, \"QC_summary.csv\"), index=False)\n",
        "\n",
        "    # Save final master\n",
        "    combined.to_csv(os.path.join(out_dir, \"ALL_master_FINAL.csv\"), index=False)\n",
        "\n",
        "    # 3) Table 1 (Datasets)\n",
        "    table1 = pd.DataFrame([\n",
        "        [\"Hansen Global Forest Change\", \"treecover2000 + lossyear-derived labels\", \"30 m\", \"2000 baseline; loss 2001–2024\", \"Forest baseline + historical loss label\"],\n",
        "        [\"SRTM\", \"mean_elevation_m + mean_slope_deg\", \"30–90 m\", \"Static\", \"Terrain predictors\"],\n",
        "        [\"CHIRPS\", \"rain_last12m_total_mm + rain_mean_annual_2000_2024_mm\", \"~5 km\", \"2000–2025\", \"Rainfall predictors\"],\n",
        "    ], columns=[\"Dataset\",\"Layers/Variables\",\"Native resolution\",\"Time span\",\"Role\"])\n",
        "    table1.to_csv(os.path.join(tables_dir, \"Table1_datasets.csv\"), index=False)\n",
        "\n",
        "    # 4) Table 2 (Dataset Summary by district)\n",
        "    def summarize(group):\n",
        "        out = {\n",
        "            \"n_samples\": len(group),\n",
        "            \"n_train\": int((group[\"split\"]==\"train\").sum()),\n",
        "            \"n_test\": int((group[\"split\"]==\"test\").sum()),\n",
        "            \"pos_rate_label_std\": float(group[\"label_std\"].mean()),\n",
        "        }\n",
        "        for col in [\"treecover2000\",\"mean_elevation_m\",\"mean_slope_deg\",\"rain_last12m_total_mm\",\"rain_mean_annual_2000_2024_mm\",\"loss_first_year\"]:\n",
        "            if col in group.columns:\n",
        "                out[f\"{col}_mean\"] = float(group[col].mean())\n",
        "                out[f\"{col}_std\"] = float(group[col].std())\n",
        "        return pd.Series(out)\n",
        "\n",
        "    table2 = combined.groupby(\"district\").apply(summarize).reset_index()\n",
        "    table2.to_csv(os.path.join(tables_dir, \"Table2_dataset_summary.csv\"), index=False)\n",
        "\n",
        "    # 5) Modeling\n",
        "    meta = {\"district\",\"split\",\"lon\",\"lat\",\"label_std\",\"label\",\"defo\"}\n",
        "    label_related = {\"loss_any_2001_2024\",\"loss_first_year\"}\n",
        "    feature_cols = [\n",
        "        c for c in combined.columns\n",
        "        if c not in meta and c not in label_related and pd.api.types.is_numeric_dtype(combined[c])\n",
        "    ]\n",
        "    X = combined[feature_cols].copy().apply(lambda s: s.fillna(s.median()), axis=0)\n",
        "    y = combined[\"label_std\"].astype(int)\n",
        "\n",
        "    # Baseline score (simple)\n",
        "    baseline_cols = [c for c in [\"treecover2000\",\"mean_elevation_m\",\"mean_slope_deg\",\"rain_last12m_total_mm\"] if c in X.columns]\n",
        "    baseX = X[baseline_cols].copy()\n",
        "    if \"mean_elevation_m\" in baseX.columns: baseX[\"mean_elevation_m\"] = -baseX[\"mean_elevation_m\"]\n",
        "    if \"mean_slope_deg\" in baseX.columns: baseX[\"mean_slope_deg\"] = -baseX[\"mean_slope_deg\"]\n",
        "    baseline_prob = 1/(1+np.exp(-StandardScaler().fit_transform(baseX).mean(axis=1)))\n",
        "\n",
        "    logreg = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
        "    ])\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=400,\n",
        "        random_state=42,\n",
        "        class_weight=\"balanced_subsample\",\n",
        "        max_features=\"sqrt\",\n",
        "        max_depth=22,\n",
        "        min_samples_leaf=2,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    def eval_scenario(train_idx, test_idx, scenario_name):\n",
        "        y_tr, y_te = y.iloc[train_idx].values, y.iloc[test_idx].values\n",
        "        X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
        "\n",
        "        logreg.fit(X_tr, y_tr)\n",
        "        rf.fit(X_tr, y_tr)\n",
        "\n",
        "        base_tr, base_te = baseline_prob[train_idx], baseline_prob[test_idx]\n",
        "        lr_tr, lr_te = logreg.predict_proba(X_tr)[:,1], logreg.predict_proba(X_te)[:,1]\n",
        "        rf_tr, rf_te = rf.predict_proba(X_tr)[:,1], rf.predict_proba(X_te)[:,1]\n",
        "\n",
        "        thr_base = _best_f1_threshold(y_tr, base_tr)\n",
        "        thr_lr   = _best_f1_threshold(y_tr, lr_tr)\n",
        "        thr_rf   = _best_f1_threshold(y_tr, rf_tr)\n",
        "\n",
        "        rows = []\n",
        "        for model_name, sc, thr in [\n",
        "            (\"Baseline\", base_te, thr_base),\n",
        "            (\"LogReg\", lr_te, thr_lr),\n",
        "            (\"RF\", rf_te, thr_rf),\n",
        "        ]:\n",
        "            rows.append([\n",
        "                scenario_name,\n",
        "                model_name,\n",
        "                roc_auc_score(y_te, sc),\n",
        "                average_precision_score(y_te, sc),\n",
        "                precision_score(y_te, (sc>=thr).astype(int), zero_division=0),\n",
        "                recall_score(y_te, (sc>=thr).astype(int), zero_division=0),\n",
        "                f1_score(y_te, (sc>=thr).astype(int), zero_division=0),\n",
        "                _capture_rate(y_te, sc, 0.05),\n",
        "                _capture_rate(y_te, sc, 0.10),\n",
        "                thr,\n",
        "                len(y_te),\n",
        "                int(y_te.sum())\n",
        "            ])\n",
        "\n",
        "        perf = pd.DataFrame(rows, columns=[\n",
        "            \"Scenario\",\"Model\",\"AUC\",\"AP\",\"Precision\",\"Recall\",\"F1\",\n",
        "            \"Capture@5%\",\"Capture@10%\",\"Threshold(F1-train)\",\"N_test\",\"N_pos_test\"\n",
        "        ])\n",
        "        scores = {\"Baseline\": base_te, \"LogReg\": lr_te, \"RF\": rf_te}\n",
        "        return perf, y_te, scores\n",
        "\n",
        "    # A) provided split\n",
        "    train_idx = combined.index[combined[\"split\"]==\"train\"].to_numpy()\n",
        "    test_idx  = combined.index[combined[\"split\"]==\"test\"].to_numpy()\n",
        "    t3_split, y_split, scores_split = eval_scenario(train_idx, test_idx, \"Split (provided)\")\n",
        "\n",
        "    # B) area transfer KBang -> MangYang\n",
        "    kbang_idx = combined.index[combined[\"district\"]==\"KBang\"].to_numpy()\n",
        "    mang_idx  = combined.index[combined[\"district\"]==\"MangYang\"].to_numpy()\n",
        "    t3_k2m, y_k2m, scores_k2m = eval_scenario(kbang_idx, mang_idx, \"Area transfer (KBang->MangYang)\")\n",
        "\n",
        "    table3 = pd.concat([t3_split, t3_k2m], ignore_index=True)\n",
        "    table3.to_csv(os.path.join(tables_dir, \"Table3_model_performance.csv\"), index=False)\n",
        "\n",
        "    # ROC figures\n",
        "    _save_roc(y_split, scores_split, os.path.join(figs_dir, \"Figure_ROC_split.png\"), \"ROC (provided split)\")\n",
        "    _save_roc(y_k2m, scores_k2m, os.path.join(figs_dir, \"Figure_ROC_KBang_to_MangYang.png\"), \"ROC (KBang->MangYang)\")\n",
        "\n",
        "    # 6) Explainability figures (train on provided split)\n",
        "    logreg.fit(X.iloc[train_idx], y.iloc[train_idx].values)\n",
        "    rf.fit(X.iloc[train_idx], y.iloc[train_idx].values)\n",
        "\n",
        "    importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=False).head(12)\n",
        "    plt.figure(figsize=(7,5))\n",
        "    plt.barh(list(reversed(importances.index)), list(reversed(importances.values)))\n",
        "    plt.title(\"RF feature importance (top 12)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(figs_dir, \"Figure_RF_importance.png\"), dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    coef = pd.Series(logreg.named_steps[\"clf\"].coef_[0], index=feature_cols).sort_values()\n",
        "    coef_plot = pd.concat([coef.head(8), coef.tail(8)])\n",
        "    plt.figure(figsize=(7,5))\n",
        "    plt.barh(coef_plot.index, coef_plot.values)\n",
        "    plt.title(\"LogReg coefficients (most negative/positive)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(figs_dir, \"Figure_LogReg_coefficients.png\"), dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    # 7) Predictions + warning zones\n",
        "    logreg.fit(X, y.values)\n",
        "    rf.fit(X, y.values)\n",
        "\n",
        "    pred = combined.copy()\n",
        "    pred[\"risk_baseline\"] = baseline_prob\n",
        "    pred[\"risk_logreg\"] = logreg.predict_proba(X)[:,1]\n",
        "    pred[\"risk_rf\"] = rf.predict_proba(X)[:,1]\n",
        "\n",
        "    pred[\"warn_top5_rf\"] = 0\n",
        "    pred[\"warn_top10_rf\"] = 0\n",
        "    for d in pred[\"district\"].unique():\n",
        "        sub = pred[pred[\"district\"] == d]\n",
        "        thr5 = np.quantile(sub[\"risk_rf\"], 0.95)\n",
        "        thr10 = np.quantile(sub[\"risk_rf\"], 0.90)\n",
        "        pred.loc[(pred[\"district\"]==d) & (pred[\"risk_rf\"]>=thr5), \"warn_top5_rf\"] = 1\n",
        "        pred.loc[(pred[\"district\"]==d) & (pred[\"risk_rf\"]>=thr10), \"warn_top10_rf\"] = 1\n",
        "\n",
        "    pred.to_csv(os.path.join(preds_dir, \"Model_predictions_and_warning_zones.csv\"), index=False)\n",
        "\n",
        "    # Run log\n",
        "    with open(os.path.join(out_dir, \"README_run_log.txt\"), \"w\") as f:\n",
        "        f.write(\"Pipeline run complete.\\n\")\n",
        "        f.write(f\"Rows: {len(combined)}\\n\")\n",
        "        f.write(f\"Features used: {len(feature_cols)}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"out_dir\": out_dir,\n",
        "        \"feature_cols\": feature_cols,\n",
        "        \"baseline_cols\": baseline_cols\n",
        "    }\n",
        "'''\n",
        "open(\"/content/deforestation_risk_project/src/pipeline.py\",\"w\").write(pipeline_code)\n",
        "print(\"Wrote pipeline to:\", \"/content/deforestation_risk_project/src/pipeline.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_2HSFazwO6C",
        "outputId": "136fcb97-efba-4816-ac13-eb48842922cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote pipeline to: /content/deforestation_risk_project/src/pipeline.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deforestation_risk_project.src.pipeline import run_pipeline\n",
        "\n",
        "result = run_pipeline(\n",
        "    \"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "    \"/content/KBang_TEST_master_rain_elev_lossyear.csv\",\n",
        "    \"/content/MangYang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "    \"/content/MangYang_TEST_master_rain_elev_lossyear.csv\",\n",
        "    \"/content/deforestation_risk_project/outputs\"\n",
        ")\n",
        "\n",
        "print(\"DONE. Outputs at:\", result[\"out_dir\"])\n",
        "print(\"Feature columns used:\", len(result[\"feature_cols\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM9NoCahwTXJ",
        "outputId": "74f7ee24-d881-414a-9ab3-d32f9e356d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE. Outputs at: /content/deforestation_risk_project/outputs\n",
            "Feature columns used: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = shutil.make_archive(\"/content/outputs_package\", \"zip\", \"/content/deforestation_risk_project/outputs\")\n",
        "print(\"Created:\", zip_path)\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ynv3fqpowZID",
        "outputId": "a6528c6e-aab9-446d-e823-b01af323fc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: /content/outputs_package.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_181d0723-23b0-4dd6-8804-b53e092ea540\", \"outputs_package.zip\", 1164346)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.pipeline import run_pipeline\n",
        "\n",
        "run_pipeline(\n",
        "  \"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/KBang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/outputs\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "-3oZdFHt2hpP",
        "outputId": "d28f133a-26e1-44da-f531-f787ac446b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2495498612.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m run_pipeline(\n\u001b[1;32m      4\u001b[0m   \u001b[0;34m\"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;34m\"/content/KBang_TEST_master_rain_elev_lossyear.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Borino88/deforestation-risk-gialai.git\n",
        "%cd deforestation-risk-gialai\n",
        "!pip -q install -r requirements.txt\n",
        "!ls\n",
        "!ls src\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR6mzMfv2jHH",
        "outputId": "e0f8f171-9219-4e51-9f8c-9ed88a5505ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deforestation-risk-gialai'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 23 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 10.64 KiB | 2.66 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/deforestation-risk-gialai/deforestation-risk-gialai\n",
            "README.md  requirements.txt  src\n",
            "pipeline.py  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.pipeline import run_pipeline\n",
        "\n",
        "run_pipeline(\n",
        "  \"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/KBang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/outputs\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cehr0EUQ3Lsn",
        "outputId": "cf9361b2-5ea0-482d-d0a3-01747af41208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'out_dir': '/content/outputs',\n",
              " 'feature_cols': ['elevation',\n",
              "  'label_test_period',\n",
              "  'label_train_period',\n",
              "  'mean_elevation_m',\n",
              "  'mean_slope_deg',\n",
              "  'rain_last12m_total_mm',\n",
              "  'rain_mean_annual_2000_2024_mm',\n",
              "  'rand',\n",
              "  'slope',\n",
              "  'treecover2000',\n",
              "  'B11',\n",
              "  'B12',\n",
              "  'B2',\n",
              "  'B3',\n",
              "  'B4',\n",
              "  'B8',\n",
              "  'NBR',\n",
              "  'NDVI',\n",
              "  'elev'],\n",
              " 'baseline_cols': ['treecover2000',\n",
              "  'mean_elevation_m',\n",
              "  'mean_slope_deg',\n",
              "  'rain_last12m_total_mm']}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "zip_path = shutil.make_archive(\"/content/outputs\", \"zip\", \"/content/outputs\")\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Co6pNjaO3WEW",
        "outputId": "adc3bb7f-9f7a-4b9e-85d5-93c11959cc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ec1c0849-09bb-4a04-ad2c-f38fba9934ad\", \"outputs.zip\", 1164312)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.pipeline import run_pipeline\n",
        "\n",
        "run_pipeline(\n",
        "  \"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/KBang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/outputs\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmRkfkb33YHw",
        "outputId": "dd90ee7c-daa8-4027-99d7-e67348dfaf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'out_dir': '/content/outputs',\n",
              " 'feature_cols': ['elevation',\n",
              "  'label_test_period',\n",
              "  'label_train_period',\n",
              "  'mean_elevation_m',\n",
              "  'mean_slope_deg',\n",
              "  'rain_last12m_total_mm',\n",
              "  'rain_mean_annual_2000_2024_mm',\n",
              "  'rand',\n",
              "  'slope',\n",
              "  'treecover2000',\n",
              "  'B11',\n",
              "  'B12',\n",
              "  'B2',\n",
              "  'B3',\n",
              "  'B4',\n",
              "  'B8',\n",
              "  'NBR',\n",
              "  'NDVI',\n",
              "  'elev'],\n",
              " 'baseline_cols': ['treecover2000',\n",
              "  'mean_elevation_m',\n",
              "  'mean_slope_deg',\n",
              "  'rain_last12m_total_mm']}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = shutil.make_archive(\"/content/outputs\", \"zip\", \"/content/outputs\")\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MGftAqF3GuJM",
        "outputId": "4d9649ae-85fa-4047-cb03-0d402eefe58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97bb2d9e-5821-4655-803f-02098b863e4f\", \"outputs.zip\", 1164330)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Borino88/deforestation-risk-gialai.git\n",
        "%cd deforestation-risk-gialai\n",
        "!pip -q install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WzbF1GtG1U2",
        "outputId": "006e9eac-bbf9-456e-c8d4-e0de31c3581d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deforestation-risk-gialai'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/32)\u001b[K\rremote: Counting objects:   6% (2/32)\u001b[K\rremote: Counting objects:   9% (3/32)\u001b[K\rremote: Counting objects:  12% (4/32)\u001b[K\rremote: Counting objects:  15% (5/32)\u001b[K\rremote: Counting objects:  18% (6/32)\u001b[K\rremote: Counting objects:  21% (7/32)\u001b[K\rremote: Counting objects:  25% (8/32)\u001b[K\rremote: Counting objects:  28% (9/32)\u001b[K\rremote: Counting objects:  31% (10/32)\u001b[K\rremote: Counting objects:  34% (11/32)\u001b[K\rremote: Counting objects:  37% (12/32)\u001b[K\rremote: Counting objects:  40% (13/32)\u001b[K\rremote: Counting objects:  43% (14/32)\u001b[K\rremote: Counting objects:  46% (15/32)\u001b[K\rremote: Counting objects:  50% (16/32)\u001b[K\rremote: Counting objects:  53% (17/32)\u001b[K\rremote: Counting objects:  56% (18/32)\u001b[K\rremote: Counting objects:  59% (19/32)\u001b[K\rremote: Counting objects:  62% (20/32)\u001b[K\rremote: Counting objects:  65% (21/32)\u001b[K\rremote: Counting objects:  68% (22/32)\u001b[K\rremote: Counting objects:  71% (23/32)\u001b[K\rremote: Counting objects:  75% (24/32)\u001b[K\rremote: Counting objects:  78% (25/32)\u001b[K\rremote: Counting objects:  81% (26/32)\u001b[K\rremote: Counting objects:  84% (27/32)\u001b[K\rremote: Counting objects:  87% (28/32)\u001b[K\rremote: Counting objects:  90% (29/32)\u001b[K\rremote: Counting objects:  93% (30/32)\u001b[K\rremote: Counting objects:  96% (31/32)\u001b[K\rremote: Counting objects: 100% (32/32)\u001b[K\rremote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/26)\u001b[K\rremote: Compressing objects:   7% (2/26)\u001b[K\rremote: Compressing objects:  11% (3/26)\u001b[K\rremote: Compressing objects:  15% (4/26)\u001b[K\rremote: Compressing objects:  19% (5/26)\u001b[K\rremote: Compressing objects:  23% (6/26)\u001b[K\rremote: Compressing objects:  26% (7/26)\u001b[K\rremote: Compressing objects:  30% (8/26)\u001b[K\rremote: Compressing objects:  34% (9/26)\u001b[K\rremote: Compressing objects:  38% (10/26)\u001b[K\rremote: Compressing objects:  42% (11/26)\u001b[K\rremote: Compressing objects:  46% (12/26)\u001b[K\rremote: Compressing objects:  50% (13/26)\u001b[K\rremote: Compressing objects:  53% (14/26)\u001b[K\rremote: Compressing objects:  57% (15/26)\u001b[K\rremote: Compressing objects:  61% (16/26)\u001b[K\rremote: Compressing objects:  65% (17/26)\u001b[K\rremote: Compressing objects:  69% (18/26)\u001b[K\rremote: Compressing objects:  73% (19/26)\u001b[K\rremote: Compressing objects:  76% (20/26)\u001b[K\rremote: Compressing objects:  80% (21/26)\u001b[K\rremote: Compressing objects:  84% (22/26)\u001b[K\rremote: Compressing objects:  88% (23/26)\u001b[K\rremote: Compressing objects:  92% (24/26)\u001b[K\rremote: Compressing objects:  96% (25/26)\u001b[K\rremote: Compressing objects: 100% (26/26)\u001b[K\rremote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "Receiving objects:   3% (1/32)\rReceiving objects:   6% (2/32)\rremote: Total 32 (delta 9), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects:   9% (3/32)\rReceiving objects:  12% (4/32)\rReceiving objects:  15% (5/32)\rReceiving objects:  18% (6/32)\rReceiving objects:  21% (7/32)\rReceiving objects:  25% (8/32)\rReceiving objects:  28% (9/32)\rReceiving objects:  31% (10/32)\rReceiving objects:  34% (11/32)\rReceiving objects:  37% (12/32)\rReceiving objects:  40% (13/32)\rReceiving objects:  43% (14/32)\rReceiving objects:  46% (15/32)\rReceiving objects:  50% (16/32)\rReceiving objects:  53% (17/32)\rReceiving objects:  56% (18/32)\rReceiving objects:  59% (19/32)\rReceiving objects:  62% (20/32)\rReceiving objects:  65% (21/32)\rReceiving objects:  68% (22/32)\rReceiving objects:  71% (23/32)\rReceiving objects:  75% (24/32)\rReceiving objects:  78% (25/32)\rReceiving objects:  81% (26/32)\rReceiving objects:  84% (27/32)\rReceiving objects:  87% (28/32)\rReceiving objects:  90% (29/32)\rReceiving objects:  93% (30/32)\rReceiving objects:  96% (31/32)\rReceiving objects: 100% (32/32)\rReceiving objects: 100% (32/32), 13.46 KiB | 4.49 MiB/s, done.\n",
            "Resolving deltas:   0% (0/9)\rResolving deltas:  11% (1/9)\rResolving deltas:  22% (2/9)\rResolving deltas:  33% (3/9)\rResolving deltas:  44% (4/9)\rResolving deltas:  55% (5/9)\rResolving deltas:  66% (6/9)\rResolving deltas:  77% (7/9)\rResolving deltas:  88% (8/9)\rResolving deltas: 100% (9/9)\rResolving deltas: 100% (9/9), done.\n",
            "/content/deforestation-risk-gialai/deforestation-risk-gialai/deforestation-risk-gialai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "sys.path.append(\"/content/deforestation-risk-gialai\")  # IMPORTANT\n",
        "\n",
        "from src.pipeline import run_pipeline\n",
        "\n",
        "run_pipeline(\n",
        "  \"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/KBang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/outputs\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gaan5v_QLeg4",
        "outputId": "4adef8ca-6e95-4912-f42c-98b268f26936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'out_dir': '/content/outputs',\n",
              " 'feature_cols': ['elevation',\n",
              "  'label_test_period',\n",
              "  'label_train_period',\n",
              "  'mean_elevation_m',\n",
              "  'mean_slope_deg',\n",
              "  'rain_last12m_total_mm',\n",
              "  'rain_mean_annual_2000_2024_mm',\n",
              "  'rand',\n",
              "  'slope',\n",
              "  'treecover2000',\n",
              "  'B11',\n",
              "  'B12',\n",
              "  'B2',\n",
              "  'B3',\n",
              "  'B4',\n",
              "  'B8',\n",
              "  'NBR',\n",
              "  'NDVI',\n",
              "  'elev'],\n",
              " 'baseline_cols': ['treecover2000',\n",
              "  'mean_elevation_m',\n",
              "  'mean_slope_deg',\n",
              "  'rain_last12m_total_mm']}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = shutil.make_archive(\"/content/outputs\", \"zip\", \"/content/outputs\")\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lXoKcWV5Lkl7",
        "outputId": "f7d64eed-7e7c-4bc7-8cdb-e5be6236dcf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d1892f34-9120-4704-92e5-59cc23f8459c\", \"outputs.zip\", 1164367)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Borino88/deforestation-risk-gialai.git\n",
        "%cd deforestation-risk-gialai\n",
        "!pip -q install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "8Zx70VlFLv_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37b4bf6-e649-4f70-986a-7fc521b2ae54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deforestation-risk-gialai'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 37 (delta 11), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (37/37), 14.41 KiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "/content/deforestation-risk-gialai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "print(\"Uploaded:\", list(uploaded.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "4orOlg9keiLu",
        "outputId": "3150587a-9637-4e05-cfb8-7cc75eb1b05d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c91f6e1-54b4-48c8-af98-9b72bc0156f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9c91f6e1-54b4-48c8-af98-9b72bc0156f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving KBang_TEST_master_rain_elev_lossyear.csv to KBang_TEST_master_rain_elev_lossyear.csv\n",
            "Saving KBang_TRAIN_master_rain_elev_lossyear.csv to KBang_TRAIN_master_rain_elev_lossyear.csv\n",
            "Saving MangYang_TEST_master_rain_elev_lossyear.csv to MangYang_TEST_master_rain_elev_lossyear.csv\n",
            "Saving MangYang_TRAIN_master_rain_elev_lossyear.csv to MangYang_TRAIN_master_rain_elev_lossyear.csv\n",
            "Uploaded: ['KBang_TEST_master_rain_elev_lossyear.csv', 'KBang_TRAIN_master_rain_elev_lossyear.csv', 'MangYang_TEST_master_rain_elev_lossyear.csv', 'MangYang_TRAIN_master_rain_elev_lossyear.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from src.pipeline import run_pipeline\n",
        "\n",
        "out_dir = \"/content/outputs\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "run_pipeline(\n",
        "  \"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/KBang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  out_dir\n",
        ")\n",
        "\n",
        "print(\"DONE. Outputs saved to:\", out_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "eglPfvEpelxg",
        "outputId": "3d6423a7-ae1e-4c45-d75c-91450b670bc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/KBang_TRAIN_master_rain_elev_lossyear.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1359706471.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m run_pipeline(\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;34m\"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;34m\"/content/KBang_TEST_master_rain_elev_lossyear.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deforestation-risk-gialai/src/pipeline.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(kbang_train_path, kbang_test_path, mang_train_path, mang_test_path, out_dir)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# 1) Load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     dfs = {\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;34m\"KBang_train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkbang_train_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;34m\"KBang_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkbang_test_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m\"MangYang_train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmang_train_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/KBang_TRAIN_master_rain_elev_lossyear.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from src.pipeline import run_pipeline\n",
        "\n",
        "out_dir = \"/content/outputs\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "run_pipeline(\n",
        "  \"/content/KBang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/KBang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TRAIN_master_rain_elev_lossyear.csv\",\n",
        "  \"/content/MangYang_TEST_master_rain_elev_lossyear.csv\",\n",
        "  out_dir\n",
        ")\n",
        "\n",
        "print(\"DONE. Outputs saved to:\", out_dir)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me_VX3A8e8-a",
        "outputId": "9841f91f-7b41-41d7-e778-bbd3a1d71811"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE. Outputs saved to: /content/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = shutil.make_archive(\"/content/outputs_package\", \"zip\", \"/content/outputs\")\n",
        "print(\"Created:\", zip_path)\n",
        "files.download(zip_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VRiUdrNugcmu",
        "outputId": "f46dcf40-8654-43be-c08c-4ef1f1da0882"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: /content/outputs_package.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6d969f9e-d647-4c4a-95f7-72520ee2b17e\", \"outputs_package.zip\", 1164319)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TCwAF5pDgdn8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}